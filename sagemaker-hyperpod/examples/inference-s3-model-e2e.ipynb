{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "272e757b-fa70-479e-b7f2-c37eb8fba78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orchestrator    Cluster Name\n",
      "--------------  ----------------------------\n",
      "EKS             hp-cluster-for-inf-Beta2try1\n",
      "Updated context arn:aws:eks:us-east-2:637423555983:cluster/EKSClusterForInf-Beta2try1 in /tmp/kubeconfig\n",
      "Successfully set current cluster as: hp-cluster-for-inf-Beta2try1\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.hyperpod.hyperpod_manager import HyperPodManager\n",
    "\n",
    "HyperPodManager.list_clusters(region='us-east-2')\n",
    "HyperPodManager.set_context('hp-cluster-for-inf-Beta2try1', region='us-east-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff887c1-e56e-4f56-9c81-023212e37b7e",
   "metadata": {},
   "source": [
    "### Create deployment from spec object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f9e50c7-497c-420d-8a8a-3f3eac2fd893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.hyperpod.inference.config.hp_endpoint_config import CloudWatchTrigger, PrometheusTrigger, AutoScalingSpec, ModelMetrics, Metrics, FsxStorage, S3Storage, ModelSourceConfig, Tags, TlsConfig, ConfigMapKeyRef, FieldRef, ResourceFieldRef, SecretKeyRef, ValueFrom, EnvironmentVariables, ModelInvocationPort, ModelVolumeMount, Claims, Resources, Worker\n",
    "from sagemaker.hyperpod.inference.hp_endpoint import HPEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2179fa7-49a4-4211-a42e-724e7f54d3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tls_config=TlsConfig(tls_certificate_output_s3_uri='s3://tls-bucket-inf1-beta2')\n",
    "\n",
    "model_source_config = ModelSourceConfig(\n",
    "    model_source_type='s3',\n",
    "    model_location=\"deepseek15b\",\n",
    "    s3_storage=S3Storage(\n",
    "        bucket_name='test-model-s3-zhaoqi',\n",
    "        region='us-east-2',\n",
    "    ),\n",
    ")\n",
    "\n",
    "environment_variables = [\n",
    "    EnvironmentVariables(name=\"HF_MODEL_ID\", value=\"/opt/ml/model\"),\n",
    "    EnvironmentVariables(name=\"SAGEMAKER_PROGRAM\", value=\"inference.py\"),\n",
    "    EnvironmentVariables(name=\"SAGEMAKER_SUBMIT_DIRECTORY\", value=\"/opt/ml/model/code\"),\n",
    "    EnvironmentVariables(name=\"MODEL_CACHE_ROOT\", value=\"/opt/ml/model\"),\n",
    "    EnvironmentVariables(name=\"SAGEMAKER_ENV\", value=\"1\"),\n",
    "]\n",
    "\n",
    "worker = Worker(\n",
    "    image='763104351884.dkr.ecr.us-east-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.4.0-tgi2.3.1-gpu-py311-cu124-ubuntu22.04-v2.0',\n",
    "    model_volume_mount=ModelVolumeMount(\n",
    "        name='model-weights',\n",
    "    ),\n",
    "    model_invocation_port=ModelInvocationPort(container_port=8080),\n",
    "    resources=Resources(\n",
    "            requests={\"cpu\": \"30000m\", \"nvidia.com/gpu\": 1, \"memory\": \"100Gi\"},\n",
    "            limits={\"nvidia.com/gpu\": 1}\n",
    "    ),\n",
    "    environment_variables=environment_variables,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a63a543e-1762-4035-b89a-76971a55ed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_endpoint = HPEndpoint(\n",
    "    endpoint_name='test-endpoint-name-zhaoqi-06-28-1',\n",
    "    instance_type='ml.g5.8xlarge',\n",
    "    model_name='deepseek15b-test-zhaoqi-06-28-1',\n",
    "    tls_config=tls_config,\n",
    "    model_source_config=model_source_config,\n",
    "    worker=worker,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b0ff3e2-217b-4785-974c-c9d1b4c173d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deploying model and its endpoint... The process may take a few minutes.\n"
     ]
    }
   ],
   "source": [
    "s3_endpoint.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f065099-8453-4481-a061-06344d36430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_endpoint.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80babbaf-4291-4415-a430-bda66d805291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endpointName: test-endpoint-name-zhaoqi-06-28-1\n",
      "instanceType: ml.g5.8xlarge\n",
      "invocationEndpoint: invocations\n",
      "modelName: deepseek15b-test-zhaoqi-06-28-1\n",
      "modelSourceConfig:\n",
      "  modelLocation: deepseek15b\n",
      "  modelSourceType: s3\n",
      "  prefetchEnabled: false\n",
      "  s3Storage:\n",
      "    bucketName: test-model-s3-zhaoqi\n",
      "    region: us-east-2\n",
      "namespace: default\n",
      "replicas: 1\n",
      "status:\n",
      "  conditions:\n",
      "  - lastTransitionTime: '2025-06-29T00:51:21Z'\n",
      "    message: Deployment or SageMaker endpoint registration creation for model is in\n",
      "      progress\n",
      "    reason: InProgress\n",
      "    status: 'True'\n",
      "    type: DeploymentInProgress\n",
      "  - lastTransitionTime: '2025-06-29T00:56:36Z'\n",
      "    message: Deployment and SageMaker endpoint registration for model have been created\n",
      "      successfully\n",
      "    reason: Success\n",
      "    status: 'True'\n",
      "    type: DeploymentComplete\n",
      "  deploymentStatus:\n",
      "    deploymentObjectOverallState: DeploymentComplete\n",
      "    lastUpdated: '2025-06-29T00:56:37Z'\n",
      "    name: deepseek15b-test-zhaoqi-06-28-1\n",
      "    reason: NativeDeploymentObjectFound\n",
      "    status:\n",
      "      availableReplicas: 1\n",
      "      conditions:\n",
      "      - lastTransitionTime: '2025-06-29T00:51:22Z'\n",
      "        lastUpdateTime: '2025-06-29T00:51:22Z'\n",
      "        message: Deployment has minimum availability.\n",
      "        reason: MinimumReplicasAvailable\n",
      "        status: 'True'\n",
      "        type: Available\n",
      "      - lastTransitionTime: '2025-06-29T00:51:16Z'\n",
      "        lastUpdateTime: '2025-06-29T00:51:22Z'\n",
      "        message: ReplicaSet \"deepseek15b-test-zhaoqi-06-28-1-69c5b9dccc\" has successfully\n",
      "          progressed.\n",
      "        reason: NewReplicaSetAvailable\n",
      "        status: 'True'\n",
      "        type: Progressing\n",
      "      observedGeneration: 1\n",
      "      readyReplicas: 1\n",
      "      replicas: 1\n",
      "      updatedReplicas: 1\n",
      "  endpoints:\n",
      "    sagemaker:\n",
      "      endpointArn: arn:aws:sagemaker:us-east-2:637423555983:endpoint/test-endpoint-name-zhaoqi-06-28-1\n",
      "      state: CreationCompleted\n",
      "  replicas: 1\n",
      "  selector: app=deepseek15b-test-zhaoqi-06-28-1,deploying-service=hyperpod-inference\n",
      "  state: DeploymentComplete\n",
      "  tlsCertificate:\n",
      "    certificateARN: arn:aws:acm:us-east-2:637423555983:certificate/c6ab6d10-64d5-47fd-b680-de7ed9de9c50\n",
      "    certificateDomainNames:\n",
      "    - internal-k8s-default-albdeeps-ca3ba5de5b-1015113547.us-east-2.elb.amazonaws.com\n",
      "    certificateName: deepseek15b-test-zhaoqi-06-28-1-certificate\n",
      "    importedCertificates:\n",
      "    - arn:aws:acm:us-east-2:637423555983:certificate/c6ab6d10-64d5-47fd-b680-de7ed9de9c50\n",
      "    issuerName: deepseek15b-test-zhaoqi-06-28-1-issuer\n",
      "    lastCertExpiryTime: '2026-06-29T00:51:21Z'\n",
      "    tlsCertificateOutputS3Bucket: tls-bucket-inf1-beta2\n",
      "    tlsCertificateS3Keys:\n",
      "    - 52c2qrh8q2ts/default-deepseek15b-test-zhaoqi-06-28-1-1751158276/deepseek15b-test-zhaoqi-06-28-1-certificate-1782694281.pem\n",
      "tlsConfig:\n",
      "  tlsCertificateOutputS3Uri: s3://tls-bucket-inf1-beta2\n",
      "worker:\n",
      "  environmentVariables:\n",
      "  - name: HF_MODEL_ID\n",
      "    value: /opt/ml/model\n",
      "  - name: SAGEMAKER_PROGRAM\n",
      "    value: inference.py\n",
      "  - name: SAGEMAKER_SUBMIT_DIRECTORY\n",
      "    value: /opt/ml/model/code\n",
      "  - name: MODEL_CACHE_ROOT\n",
      "    value: /opt/ml/model\n",
      "  - name: SAGEMAKER_ENV\n",
      "    value: '1'\n",
      "  image: 763104351884.dkr.ecr.us-east-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.4.0-tgi2.3.1-gpu-py311-cu124-ubuntu22.04-v2.0\n",
      "  modelInvocationPort:\n",
      "    containerPort: 8080\n",
      "    name: http\n",
      "  modelVolumeMount:\n",
      "    mountPath: /opt/ml/model\n",
      "    name: model-weights\n",
      "  resources:\n",
      "    limits:\n",
      "      nvidia.com/gpu: 1\n",
      "    requests:\n",
      "      cpu: 30000m\n",
      "      memory: 100Gi\n",
      "      nvidia.com/gpu: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print refreshed config\n",
    "import yaml\n",
    "print(yaml.dump(s3_endpoint.model_dump(exclude_none=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fae35b-e9c4-4bbd-b34c-a43a9049b929",
   "metadata": {},
   "source": [
    "### List all endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78f12fa4-7547-46fb-9680-3f0101f722d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HPEndpoint(InitialReplicaCount=None, autoScalingSpec=None, endpointName='test-endpoint-name-fsx-zhaoqi-pysdk', instanceType='ml.g5.8xlarge', invocationEndpoint='invocations', metrics=None, modelName='deepseek15b-fsx-test-zhaoqi-pysdk', modelSourceConfig=ModelSourceConfig(fsxStorage=FsxStorage(dnsName=None, fileSystemId='fs-0e6a92495c35a81f2', mountName=None), modelLocation='deepseek-1-5b', modelSourceType='fsx', prefetchEnabled=False, s3Storage=None), modelVersion=None, replicas=1, tags=None, tlsConfig=TlsConfig(tlsCertificateOutputS3Uri='s3://tls-bucket-inf1-beta2'), worker=Worker(environmentVariables=[EnvironmentVariables(name='HF_MODEL_ID', value='/opt/ml/model', valueFrom=None), EnvironmentVariables(name='SAGEMAKER_PROGRAM', value='inference.py', valueFrom=None), EnvironmentVariables(name='SAGEMAKER_SUBMIT_DIRECTORY', value='/opt/ml/model/code', valueFrom=None), EnvironmentVariables(name='MODEL_CACHE_ROOT', value='/opt/ml/model', valueFrom=None), EnvironmentVariables(name='SAGEMAKER_ENV', value='1', valueFrom=None)], image='763104351884.dkr.ecr.us-east-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.4.0-tgi2.3.1-gpu-py311-cu124-ubuntu22.04-v2.0', modelInvocationPort=ModelInvocationPort(containerPort=8080, name='http'), modelVolumeMount=ModelVolumeMount(mountPath='/opt/ml/model', name='model-weights'), resources=Resources(claims=None, limits={'nvidia.com/gpu': 1}, requests={'cpu': '30000m', 'memory': '100Gi', 'nvidia.com/gpu': 1})), namespace='default', status=None),\n",
       " HPEndpoint(InitialReplicaCount=None, autoScalingSpec=None, endpointName='test-endpoint-name-zhaoqi-06-28-1', instanceType='ml.g5.8xlarge', invocationEndpoint='invocations', metrics=None, modelName='deepseek15b-test-zhaoqi-06-28-1', modelSourceConfig=ModelSourceConfig(fsxStorage=None, modelLocation='deepseek15b', modelSourceType='s3', prefetchEnabled=False, s3Storage=S3Storage(bucketName='test-model-s3-zhaoqi', region='us-east-2')), modelVersion=None, replicas=1, tags=None, tlsConfig=TlsConfig(tlsCertificateOutputS3Uri='s3://tls-bucket-inf1-beta2'), worker=Worker(environmentVariables=[EnvironmentVariables(name='HF_MODEL_ID', value='/opt/ml/model', valueFrom=None), EnvironmentVariables(name='SAGEMAKER_PROGRAM', value='inference.py', valueFrom=None), EnvironmentVariables(name='SAGEMAKER_SUBMIT_DIRECTORY', value='/opt/ml/model/code', valueFrom=None), EnvironmentVariables(name='MODEL_CACHE_ROOT', value='/opt/ml/model', valueFrom=None), EnvironmentVariables(name='SAGEMAKER_ENV', value='1', valueFrom=None)], image='763104351884.dkr.ecr.us-east-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.4.0-tgi2.3.1-gpu-py311-cu124-ubuntu22.04-v2.0', modelInvocationPort=ModelInvocationPort(containerPort=8080, name='http'), modelVolumeMount=ModelVolumeMount(mountPath='/opt/ml/model', name='model-weights'), resources=Resources(claims=None, limits={'nvidia.com/gpu': 1}, requests={'cpu': '30000m', 'memory': '100Gi', 'nvidia.com/gpu': 1})), namespace='default', status=None)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoints = HPEndpoint.list()\n",
    "endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b9937c-bc5d-442e-a4ef-b83b2375cd8b",
   "metadata": {},
   "source": [
    "### Invoke endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5dae2d3-9744-4c76-b9f4-d8590cfe2fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = HPEndpoint.get(name='deepseek15b-test-zhaoqi-06-28-1')\n",
    "\n",
    "# another way to get endpoint object\n",
    "# endpoint = HPEndpoint.list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "549e857f-921b-40b0-8c75-2f894d44deb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'[{\"generated_text\":\"What is the capital of Japan? How about its population? What else? Answer in letters.\\\\nOkay, so I need to figure out the capital of Japan and its population, and then provide some additional information. The user has also specified the format, but it\\'s not entirely clear from the start. Let me parse that again.\\\\n\\\\nThe user wrote: \\\\\"What is the capital of Japan? How about its population? What else? Answer in letters.\\\\\"\\\\n\\\\nHmm, that\\'s a bit vague. The \\\\\"Answer in letters\\\\\" suggests that the\"}]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data='{\"inputs\": \"What is the capital of Japan?\"}'\n",
    "\n",
    "# invoke\n",
    "response=endpoint.invoke(body=data, content_type='application/json')\n",
    "response.body.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56fcf32-d66d-4f1a-bc05-9eea4c9847b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
