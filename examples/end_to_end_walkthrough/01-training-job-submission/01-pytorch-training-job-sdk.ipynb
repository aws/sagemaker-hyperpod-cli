{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0704685",
   "metadata": {},
   "source": [
    "# Submitting a PyTorch Training Job - HyperPod CLI End-to-End Walkthrough\n",
    "\n",
    "This example shows how to fine-tune a **Qwen3 4B Thinking** model using PyTorch FSDP and QLora on your HyperPod cluster.\n",
    "\n",
    "This example assumes that you completed the **Setup instructions** in [00-getting-started/00-setup.md](../00-getting-started/00-setup.md) as well as the **Training Dataset** and **Training Docker Image** steps in [00-pytorch-training-job.md](00-pytorch-training-job.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece29d2a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Import necessary classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e23d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.hyperpod.training import (\n",
    "    HyperPodPytorchJob,\n",
    "    Containers,\n",
    "    ReplicaSpec,\n",
    "    Resources,\n",
    "    RunPolicy,\n",
    "    Spec,\n",
    "    Template,\n",
    "    Volumes,\n",
    "    VolumeMounts,\n",
    ")\n",
    "from sagemaker.hyperpod.common.config import Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00703dfd",
   "metadata": {},
   "source": [
    "### Define the environment variables\n",
    "\n",
    "Please use the values according to the steps executed in [00-pytorch-training-job.md](00-pytorch-training-job.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081c1821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration variables\n",
    "AWS_REGION = \"PLEASE_FILL_IN\"\n",
    "AWS_ACCOUNT_ID = \"PLEASE_FILL_IN\"\n",
    "\n",
    "S3_PREFIX = \"qwen-cli-example\"\n",
    "ECR_NAME = \"qwen3-finetuning\"\n",
    "DOCKER_IMAGE_TAG = \"pytorch2.8-cu129\"\n",
    "JOB_NAME = \"qwen3-4b-thinking-2507-fsdp\"\n",
    "\n",
    "IMAGE_URI = f\"{AWS_ACCOUNT_ID}.dkr.ecr.{AWS_REGION}.amazonaws.com/{ECR_NAME}:{DOCKER_IMAGE_TAG}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f277ec8",
   "metadata": {},
   "source": [
    "### Define the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3c01d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_job = HyperPodPytorchJob(\n",
    "    metadata=Metadata(name=JOB_NAME, namespace=\"default\"),\n",
    "    nproc_per_node=\"4\",\n",
    "    replica_specs=[\n",
    "        ReplicaSpec(\n",
    "            name=\"pod\",\n",
    "            replicas=2,\n",
    "            template=Template(\n",
    "                spec=Spec(\n",
    "                    containers=[\n",
    "                        Containers(\n",
    "                            name=\"training-container\",\n",
    "                            image=IMAGE_URI,\n",
    "                            image_pull_policy=\"IfNotPresent\",\n",
    "                            command=[\"hyperpodrun\", \"--nnodes=2:2\", \"--nproc_per_node=4\", f\"/data/{S3_PREFIX}/scripts/train.py\"],\n",
    "                            args=[\"--config\", f\"/data/{S3_PREFIX}/scripts/args.yaml\"],\n",
    "                            env=[\n",
    "                                {\"name\": \"LOGLEVEL\", \"value\": \"INFO\"},\n",
    "                                {\"name\": \"PYTORCH_CUDA_ALLOC_CONF\", \"value\": \"expandable_segments:True\"},\n",
    "                                {\"name\": \"NCCL_DEBUG\", \"value\": \"INFO\"},\n",
    "                                {\"name\": \"NCCL_SOCKET_IFNAME\", \"value\": \"^lo\"},\n",
    "                                {\"name\": \"TORCH_NCCL_ASYNC_ERROR_HANDLING\", \"value\": \"1\"},\n",
    "                                {\"name\": \"FI_PROVIDER\", \"value\": \"efa\"},\n",
    "                                {\"name\": \"FI_EFA_FORK_SAFE\", \"value\": \"1\"},\n",
    "                                {\"name\": \"NCCL_PROTO\", \"value\": \"simple\"},\n",
    "                            ],\n",
    "                            resources=Resources(\n",
    "                                requests={\"nvidia.com/gpu\": \"4\"},\n",
    "                                limits={\"nvidia.com/gpu\": \"4\"},\n",
    "                            ),\n",
    "                            volume_mounts=[\n",
    "                                VolumeMounts(name=\"shmem\", mount_path=\"/dev/shm\"),\n",
    "                                VolumeMounts(name=\"local\", mount_path=\"/local\"),\n",
    "                                VolumeMounts(name=\"fsx-volume\", mount_path=\"/data\"),\n",
    "                            ],\n",
    "                        )\n",
    "                    ],\n",
    "                    volumes=[\n",
    "                        Volumes(name=\"shmem\", host_path={\"path\": \"/dev/shm\"}),\n",
    "                        Volumes(name=\"local\", host_path={\"path\": \"/mnt/k8s-disks/0\"}),\n",
    "                        Volumes(name=\"fsx-volume\", persistent_volume_claim={\"claim_name\": \"fsx-claim\"}),\n",
    "                    ]\n",
    "                )\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    "    run_policy=RunPolicy(\n",
    "        clean_pod_policy=\"None\",\n",
    "        job_max_retry_count=100\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a136da1",
   "metadata": {},
   "source": [
    "### Submit the training job to the HyperPod cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3c3a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_job.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7069549d",
   "metadata": {},
   "source": [
    "### Monitor the job status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522aeadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"List all jobs:\")\n",
    "print(HyperPodPytorchJob.list())\n",
    "\n",
    "print(\"\\nRefresh job and check status:\")\n",
    "pytorch_job.refresh()\n",
    "print(pytorch_job.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bcacb8",
   "metadata": {},
   "source": [
    "### List pods and show the training logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b1c723",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"List all pods:\")\n",
    "print(pytorch_job.list_pods())\n",
    "\n",
    "print(\"\\nLogs from pod-0:\")\n",
    "print(pytorch_job.get_logs_from_pod(f\"{JOB_NAME}-pod-0\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db357b4",
   "metadata": {},
   "source": [
    "### Delete the Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ffeb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_job.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
