{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker HyperPod Cluster Creation - SDK Experience\n",
    "\n",
    "This notebook demonstrates the complete end-to-end workflow for creating a SageMaker HyperPod cluster using the HyperPod SDK with the HpClusterStack class. The SDK provides programmatic control over cluster lifecycle management.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- AWS CLI configured with appropriate permissions\n",
    "- SageMaker HyperPod SDK installed (`pip install sagemaker-hyperpod`)\n",
    "- SageMaker Core SDK installed (`pip install sagemaker-core`)\n",
    "- Python 3.8+ environment\n",
    "\n",
    "## Workflow Overview\n",
    "\n",
    "1. **Initialize** - Create HpClusterStack instance with configuration\n",
    "2. **Configure** - Set cluster settings and tags programmatically\n",
    "3. **Create** - Deploy the cluster infrastructure\n",
    "4. **Monitor** - Check cluster status and manage lifecycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries and Initialize Configuration\n",
    "\n",
    "First, we'll import the necessary SDK components and create an HpClusterStack instance with default settings. This is equivalent to `hyp init cluster-stack` in the CLI.\n",
    "\n",
    "**What this does:**\n",
    "- Imports HpClusterStack and related classes\n",
    "- Creates cluster configuration with default settings\n",
    "- Sets up basic infrastructure components (VPC, EKS, S3, etc.)\n",
    "- Generates unique resource names to avoid conflicts"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import uuid\n",
    "import time\n",
    "from sagemaker.hyperpod.cluster_management.hp_cluster_stack import HpClusterStack\n",
    "from sagemaker_core.main.resources import Cluster\n",
    "\n",
    "# Generate unique resource prefix to avoid conflicts\n",
    "resource_prefix = f\"hyperpod-sdk-{str(uuid.uuid4())[:8]}\"\n",
    "\n",
    "# Initialize cluster stack configuration (equivalent to hyp init cluster-stack)\n",
    "cluster_stack = HpClusterStack(\n",
    "    stage=\"prod\",\n",
    "    resource_name_prefix=resource_prefix,\n",
    "    hyperpod_cluster_name=f\"{resource_prefix}-cluster\",\n",
    "    eks_cluster_name=f\"{resource_prefix}-eks\",\n",
    "    s3_bucket_name=f\"{resource_prefix}-s3-bucket\",\n",
    "    sagemaker_iam_role_name=f\"{resource_prefix}-iam-role\",\n",
    "    \n",
    "    # Infrastructure components to create\n",
    "    create_vpc_stack=True,\n",
    "    create_security_group_stack=True,\n",
    "    create_eks_cluster_stack=True,\n",
    "    create_s3_bucket_stack=True,\n",
    "    create_s3_endpoint_stack=True,\n",
    "    create_life_cycle_script_stack=True,\n",
    "    create_sagemaker_iam_role_stack=True,\n",
    "    create_helm_chart_stack=True,\n",
    "    create_hyperpod_cluster_stack=True,\n",
    "    create_fsx_stack=True,\n",
    "    \n",
    "    # Network configuration\n",
    "    vpc_cidr=\"10.192.0.0/16\",\n",
    "    availability_zone_ids=[\"use2-az1\", \"use2-az2\", \"use2-az3\"],\n",
    "    \n",
    "    # Kubernetes configuration\n",
    "    kubernetes_version=\"1.31\",\n",
    "    node_provisioning_mode=\"Continuous\",\n",
    "    \n",
    "    # Instance group configuration\n",
    "    instance_group_settings=[\n",
    "        {\n",
    "            \"InstanceCount\": 1,\n",
    "            \"InstanceGroupName\": \"controller-group\",\n",
    "            \"InstanceType\": \"ml.t3.medium\",\n",
    "            \"TargetAvailabilityZoneId\": \"use2-az2\",\n",
    "            \"ThreadsPerCore\": 1,\n",
    "            \"InstanceStorageConfigs\": [\n",
    "                {\"EbsVolumeConfig\": {\"VolumeSizeInGB\": 500}}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Initialized cluster stack with prefix: {resource_prefix}\")\n",
    "print(f\"Cluster name: {cluster_stack.hyperpod_cluster_name}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Configure Cluster Settings and Tags\n",
    "\n",
    "Configure the cluster with custom tags and additional settings. This is equivalent to `hyp configure --tags []` in the CLI.\n",
    "\n",
    "**Key configuration options:**\n",
    "- **Tags**: For resource organization and cost tracking\n",
    "- **Instance Groups**: Define compute resources and their specifications\n",
    "- **Networking**: VPC, subnets, and security group settings\n",
    "- **Storage**: FSx and EBS volume configurations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Configure cluster with custom tags (equivalent to hyp configure --tags)\n",
    "cluster_tags = [\n",
    "    {\"Key\": \"Environment\", \"Value\": \"Development\"},\n",
    "    {\"Key\": \"Project\", \"Value\": \"MLTraining\"},\n",
    "    {\"Key\": \"Owner\", \"Value\": \"DataScienceTeam\"},\n",
    "    {\"Key\": \"CostCenter\", \"Value\": \"ML-Research\"},\n",
    "    {\"Key\": \"CreatedBy\", \"Value\": \"SDK-Example\"}\n",
    "]\n",
    "\n",
    "# Update cluster stack with tags\n",
    "cluster_stack.tags = cluster_tags\n",
    "\n",
    "# Additional configuration options\n",
    "cluster_stack.node_recovery = \"Automatic\"\n",
    "cluster_stack.fsx_availability_zone_id = \"use2-az2\"\n",
    "cluster_stack.storage_capacity = 1200\n",
    "cluster_stack.per_unit_storage_throughput = 250\n",
    "\n",
    "print(\"Configured cluster with custom tags:\")\n",
    "for tag in cluster_tags:\n",
    "    print(f\"  {tag['Key']}: {tag['Value']}\")\n",
    "\n",
    "print(f\"\\nNode recovery: {cluster_stack.node_recovery}\")\n",
    "print(f\"FSx storage capacity: {cluster_stack.storage_capacity} GiB\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Current Configuration\n",
    "\n",
    "Let's examine the current configuration to understand what will be deployed:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Display current configuration details\n",
    "print(\"=== Cluster Configuration ===\")\n",
    "print(f\"Resource Prefix: {cluster_stack.resource_name_prefix}\")\n",
    "print(f\"HyperPod Cluster: {cluster_stack.hyperpod_cluster_name}\")\n",
    "print(f\"EKS Cluster: {cluster_stack.eks_cluster_name}\")\n",
    "print(f\"S3 Bucket: {cluster_stack.s3_bucket_name}\")\n",
    "print(f\"VPC CIDR: {cluster_stack.vpc_cidr}\")\n",
    "print(f\"Kubernetes Version: {cluster_stack.kubernetes_version}\")\n",
    "print(f\"\\nInstance Groups:\")\n",
    "for ig in cluster_stack.instance_group_settings:\n",
    "    print(f\"  - {ig['InstanceGroupName']}: {ig['InstanceCount']}x {ig['InstanceType']}\")\n",
    "print(f\"\\nInfrastructure Components:\")\n",
    "print(f\"  VPC Stack: {cluster_stack.create_vpc_stack}\")\n",
    "print(f\"  EKS Stack: {cluster_stack.create_eks_cluster_stack}\")\n",
    "print(f\"  HyperPod Stack: {cluster_stack.create_hyperpod_cluster_stack}\")\n",
    "print(f\"  FSx Stack: {cluster_stack.create_fsx_stack}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create the Cluster\n",
    "\n",
    "Deploy the HyperPod cluster infrastructure using the SDK. This is equivalent to `hyp create` in the CLI.\n",
    "\n",
    "**Deployment includes:**\n",
    "- VPC and networking infrastructure\n",
    "- EKS cluster with managed node groups\n",
    "- SageMaker HyperPod cluster\n",
    "- IAM roles and policies\n",
    "- S3 buckets for artifacts\n",
    "- FSx file system (if configured)\n",
    "\n",
    "**Note:** This process typically takes 15-30 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create the HyperPod cluster (equivalent to hyp create)\n",
    "try:\n",
    "    print(\"Starting cluster creation...\")\n",
    "    print(f\"This will create cluster: {cluster_stack.hyperpod_cluster_name}\")\n",
    "    \n",
    "    # Deploy the cluster infrastructure\n",
    "    response = cluster_stack.create(region=\"us-east-2\")\n",
    "    \n",
    "    print(\"\\n✅ Cluster creation initiated successfully!\")\n",
    "    print(f\"Stack Name: {cluster_stack.stack_name}\")\n",
    "    print(f\"Stack ID: {cluster_stack.stack_id}\")\n",
    "    \n",
    "    # Store cluster information for later use\n",
    "    cluster_name = cluster_stack.hyperpod_cluster_name\n",
    "    stack_name = cluster_stack.stack_name\n",
    "    \n",
    "    print(f\"\\nCluster creation is in progress. This may take 15-30 minutes.\")\n",
    "    print(f\"Monitor progress in the next steps.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Cluster creation failed: {str(e)}\")\n",
    "    raise"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Monitor Cluster Creation\n",
    "\n",
    "Monitor the cluster creation progress using SDK methods. This provides real-time status updates on the deployment process."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Monitor cluster creation progress\n",
    "def monitor_cluster_creation(stack_name, max_checks=30, interval=120):\n",
    "    \"\"\"Monitor cluster creation progress\"\"\"\n",
    "    print(f\"Monitoring cluster creation progress for stack: {stack_name}\")\n",
    "    \n",
    "    for i in range(max_checks):\n",
    "        try:\n",
    "            print(f\"\\n--- Status Check {i+1}/{max_checks} ---\")\n",
    "            \n",
    "            # Check stack status\n",
    "            status = HpClusterStack.check_status(stack_name, region=\"us-east-2\")\n",
    "            print(f\"Stack Status: {status}\")\n",
    "            \n",
    "            # Check if creation is complete\n",
    "            if status == \"CREATE_COMPLETE\":\n",
    "                print(\"\\n🎉 Cluster creation completed successfully!\")\n",
    "                break\n",
    "            elif status in [\"CREATE_FAILED\", \"ROLLBACK_COMPLETE\", \"DELETE_COMPLETE\"]:\n",
    "                print(f\"\\n❌ Cluster creation failed with status: {status}\")\n",
    "                break\n",
    "            elif status == \"CREATE_IN_PROGRESS\":\n",
    "                print(\"⏳ Cluster creation still in progress...\")\n",
    "            \n",
    "            if i < max_checks - 1:  # Don't sleep on the last iteration\n",
    "                print(f\"Waiting {interval} seconds before next check...\")\n",
    "                time.sleep(interval)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error checking status: {str(e)}\")\n",
    "            break\n",
    "    \n",
    "    return status\n",
    "\n",
    "# Start monitoring (uncomment when cluster creation is initiated)\n",
    "# final_status = monitor_cluster_creation(stack_name, max_checks=5, interval=30)\n",
    "print(\"Monitoring function ready. Uncomment to start monitoring after cluster creation.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Describe Cluster Stack\n",
    "\n",
    "Get detailed information about the deployed cluster using SDK methods. This is equivalent to `hyp describe cluster-stack` in the CLI.\n",
    "\n",
    "**Information provided:**\n",
    "- Cluster status and health\n",
    "- Resource ARNs and IDs\n",
    "- Network configuration details\n",
    "- Instance group information\n",
    "- Storage configuration"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Get detailed information about the cluster stack (equivalent to hyp describe cluster-stack)\n",
    "def describe_cluster_stack(stack_name, region=\"us-east-2\"):\n",
    "    \"\"\"Describe cluster stack details\"\"\"\n",
    "    try:\n",
    "        print(f\"Describing cluster stack: {stack_name}\")\n",
    "        \n",
    "        # Get stack description\n",
    "        response = HpClusterStack.describe(stack_name, region=region)\n",
    "        \n",
    "        if response and 'Stacks' in response and len(response['Stacks']) > 0:\n",
    "            stack = response['Stacks'][0]\n",
    "            \n",
    "            print(\"\\n=== Stack Information ===\")\n",
    "            print(f\"Stack Name: {stack.get('StackName', 'N/A')}\")\n",
    "            print(f\"Stack Status: {stack.get('StackStatus', 'N/A')}\")\n",
    "            print(f\"Creation Time: {stack.get('CreationTime', 'N/A')}\")\n",
    "            print(f\"Stack ID: {stack.get('StackId', 'N/A')}\")\n",
    "            \n",
    "            # Display parameters\n",
    "            if 'Parameters' in stack:\n",
    "                print(\"\\n=== Parameters ===\")\n",
    "                for param in stack['Parameters'][:10]:  # Show first 10 parameters\n",
    "                    print(f\"  {param['ParameterKey']}: {param['ParameterValue']}\")\n",
    "            \n",
    "            # Display outputs\n",
    "            if 'Outputs' in stack:\n",
    "                print(\"\\n=== Outputs ===\")\n",
    "                for output in stack['Outputs'][:10]:  # Show first 10 outputs\n",
    "                    print(f\"  {output['OutputKey']}: {output['OutputValue']}\")\n",
    "            \n",
    "            # Display tags\n",
    "            if 'Tags' in stack:\n",
    "                print(\"\\n=== Tags ===\")\n",
    "                for tag in stack['Tags']:\n",
    "                    print(f\"  {tag['Key']}: {tag['Value']}\")\n",
    "        \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error describing stack: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Describe the cluster stack (uncomment when stack exists)\n",
    "# describe_cluster_stack(stack_name)\n",
    "print(\"Describe function ready. Use after cluster creation is complete.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: List All Cluster Stacks\n",
    "\n",
    "List all HyperPod cluster stacks in your account using SDK methods. This is equivalent to `hyp list cluster-stack` in the CLI.\n",
    "\n",
    "**Displays:**\n",
    "- All cluster stacks in the current region\n",
    "- Stack names and creation timestamps\n",
    "- Current status of each stack\n",
    "- Resource counts and types"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# List all cluster stacks (equivalent to hyp list cluster-stack)\n",
    "def list_cluster_stacks(region=\"us-east-2\"):\n",
    "    \"\"\"List all cluster stacks in the account\"\"\"\n",
    "    try:\n",
    "        print(f\"Listing cluster stacks in region: {region}\")\n",
    "        \n",
    "        # Get list of stacks\n",
    "        response = HpClusterStack.list(region=region)\n",
    "        \n",
    "        if response and 'StackSummaries' in response:\n",
    "            stacks = response['StackSummaries']\n",
    "            \n",
    "            print(f\"\\n=== Found {len(stacks)} Stack(s) ===\")\n",
    "            \n",
    "            if stacks:\n",
    "                print(f\"{'Stack Name':<40} {'Status':<25} {'Creation Time':<20}\")\n",
    "                print(\"-\" * 85)\n",
    "                \n",
    "                for stack in stacks:\n",
    "                    name = stack.get('StackName', 'N/A')[:39]\n",
    "                    status = stack.get('StackStatus', 'N/A')[:24]\n",
    "                    created = str(stack.get('CreationTime', 'N/A'))[:19]\n",
    "                    print(f\"{name:<40} {status:<25} {created:<20}\")\n",
    "            else:\n",
    "                print(\"No cluster stacks found.\")\n",
    "        \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error listing stacks: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# List all cluster stacks\n",
    "list_response = list_cluster_stacks()\n",
    "\n",
    "# Filter for HyperPod-related stacks\n",
    "if list_response and 'StackSummaries' in list_response:\n",
    "    hyperpod_stacks = [\n",
    "        stack for stack in list_response['StackSummaries']\n",
    "        if 'hyperpod' in stack.get('StackName', '').lower()\n",
    "    ]\n",
    "    \n",
    "    if hyperpod_stacks:\n",
    "        print(f\"\\n=== HyperPod Stacks ({len(hyperpod_stacks)}) ===\")\n",
    "        for stack in hyperpod_stacks:\n",
    "            print(f\"  - {stack['StackName']} ({stack['StackStatus']})\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Update Cluster Configuration\n",
    "\n",
    "Update the existing cluster configuration using sagemaker-core's Cluster class. This is equivalent to `hyp update cluster` in the CLI.\n",
    "\n",
    "**Common update scenarios:**\n",
    "- Scaling instance groups up or down\n",
    "- Adding new instance types\n",
    "- Updating cluster tags\n",
    "- Modifying storage configurations\n",
    "\n",
    "**Note:** Some changes may require cluster restart or recreation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Update cluster configuration using sagemaker-core Cluster class\n",
    "def update_cluster(cluster_name, region=\"us-east-2\"):\n",
    "    \"\"\"Update cluster configuration (equivalent to hyp update cluster)\"\"\"\n",
    "    try:\n",
    "        print(f\"Updating cluster: {cluster_name}\")\n",
    "        \n",
    "        # Get existing cluster using sagemaker-core\n",
    "        cluster = Cluster.get(cluster_name=cluster_name)\n",
    "        \n",
    "        print(f\"\\nCurrent cluster status: {cluster.cluster_status}\")\n",
    "        print(f\"Current instance groups: {len(cluster.instance_groups)}\")\n",
    "        \n",
    "        # Display current instance groups\n",
    "        print(\"\\n=== Current Instance Groups ===\")\n",
    "        for ig in cluster.instance_groups:\n",
    "            print(f\"  - {ig.instance_group_name}: {ig.current_count}x {ig.instance_type}\")\n",
    "        \n",
    "        # Example: Update cluster tags\n",
    "        updated_tags = [\n",
    "            {\"Key\": \"Environment\", \"Value\": \"Development\"},\n",
    "            {\"Key\": \"Project\", \"Value\": \"MLTraining\"},\n",
    "            {\"Key\": \"Owner\", \"Value\": \"DataScienceTeam\"},\n",
    "            {\"Key\": \"CostCenter\", \"Value\": \"ML-Research\"},\n",
    "            {\"Key\": \"UpdatedBy\", \"Value\": \"SDK-Example\"},\n",
    "            {\"Key\": \"LastUpdated\", \"Value\": str(time.time())}\n",
    "        ]\n",
    "        \n",
    "        # Update cluster with new tags\n",
    "        cluster.update(tags=updated_tags)\n",
    "        \n",
    "        print(\"\\n✅ Cluster updated successfully!\")\n",
    "        print(\"Updated tags:\")\n",
    "        for tag in updated_tags:\n",
    "            print(f\"  {tag['Key']}: {tag['Value']}\")\n",
    "        \n",
    "        return cluster\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error updating cluster: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Example: Scale instance group\n",
    "def scale_instance_group(cluster_name, instance_group_name, target_count, region=\"us-east-2\"):\n",
    "    \"\"\"Scale an instance group to target count\"\"\"\n",
    "    try:\n",
    "        print(f\"Scaling instance group '{instance_group_name}' to {target_count} instances\")\n",
    "        \n",
    "        # Get cluster\n",
    "        cluster = Cluster.get(cluster_name=cluster_name)\n",
    "        \n",
    "        # Find the instance group\n",
    "        target_ig = None\n",
    "        for ig in cluster.instance_groups:\n",
    "            if ig.instance_group_name == instance_group_name:\n",
    "                target_ig = ig\n",
    "                break\n",
    "        \n",
    "        if not target_ig:\n",
    "            print(f\"Instance group '{instance_group_name}' not found\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"Current count: {target_ig.current_count}\")\n",
    "        print(f\"Target count: {target_count}\")\n",
    "        \n",
    "        # Update instance group count\n",
    "        target_ig.target_count = target_count\n",
    "        \n",
    "        # Apply the update\n",
    "        cluster.update(instance_groups=[target_ig])\n",
    "        \n",
    "        print(f\"\\n✅ Instance group scaling initiated!\")\n",
    "        \n",
    "        return cluster\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error scaling instance group: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Update functions ready (uncomment when cluster exists)\n",
    "# updated_cluster = update_cluster(cluster_name)\n",
    "# scaled_cluster = scale_instance_group(cluster_name, \"controller-group\", 2)\n",
    "\n",
    "print(\"Update functions ready. Use after cluster creation is complete.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Verify Cluster Status and Health\n",
    "\n",
    "Verify that the cluster is healthy and ready for workloads using comprehensive status checks."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Comprehensive cluster health check\n",
    "def check_cluster_health(cluster_name, region=\"us-east-2\"):\n",
    "    \"\"\"Perform comprehensive cluster health check\"\"\"\n",
    "    try:\n",
    "        print(f\"Checking health for cluster: {cluster_name}\")\n",
    "        \n",
    "        # Get cluster details\n",
    "        cluster = Cluster.get(cluster_name=cluster_name)\n",
    "        \n",
    "        print(\"\\n=== Cluster Health Summary ===\")\n",
    "        print(f\"Cluster Name: {cluster.cluster_name}\")\n",
    "        print(f\"Cluster Status: {cluster.cluster_status}\")\n",
    "        print(f\"Creation Time: {cluster.creation_time}\")\n",
    "        print(f\"Cluster ARN: {cluster.cluster_arn}\")\n",
    "        \n",
    "        # Check instance groups health\n",
    "        print(\"\\n=== Instance Groups Health ===\")\n",
    "        total_instances = 0\n",
    "        healthy_instances = 0\n",
    "        \n",
    "        for ig in cluster.instance_groups:\n",
    "            print(f\"\\nInstance Group: {ig.instance_group_name}\")\n",
    "            print(f\"  Instance Type: {ig.instance_type}\")\n",
    "            print(f\"  Current Count: {ig.current_count}\")\n",
    "            print(f\"  Target Count: {getattr(ig, 'target_count', 'N/A')}\")\n",
    "            print(f\"  Status: {getattr(ig, 'instance_group_status', 'N/A')}\")\n",
    "            \n",
    "            total_instances += ig.current_count\n",
    "            if getattr(ig, 'instance_group_status', '') == 'InService':\n",
    "                healthy_instances += ig.current_count\n",
    "        \n",
    "        print(f\"\\n=== Overall Health ===\")\n",
    "        print(f\"Total Instances: {total_instances}\")\n",
    "        print(f\"Healthy Instances: {healthy_instances}\")\n",
    "        health_percentage = (healthy_instances / total_instances * 100) if total_instances > 0 else 0\n",
    "        print(f\"Health Percentage: {health_percentage:.1f}%\")\n",
    "        \n",
    "        # Determine overall health status\n",
    "        if cluster.cluster_status == 'InService' and health_percentage >= 80:\n",
    "            print(\"\\n🟢 Cluster is HEALTHY and ready for workloads\")\n",
    "        elif cluster.cluster_status == 'Creating':\n",
    "            print(\"\\n🟡 Cluster is still CREATING\")\n",
    "        else:\n",
    "            print(\"\\n🔴 Cluster may have ISSUES - check individual components\")\n",
    "        \n",
    "        return cluster\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error checking cluster health: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Health check function ready (uncomment when cluster exists)\n",
    "# cluster_health = check_cluster_health(cluster_name)\n",
    "\n",
    "print(\"Health check function ready. Use after cluster creation is complete.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "After successfully creating your HyperPod cluster using the SDK, you can:\n",
    "\n",
    "1. **Submit Training Jobs**: Use HyperPod SDK training classes for distributed training\n",
    "2. **Deploy Inference Endpoints**: Use HyperPod SDK inference classes for model serving\n",
    "3. **Monitor Resources**: Use SDK methods to check pod and job status\n",
    "4. **Access Logs**: Retrieve training and system logs programmatically\n",
    "5. **Scale Cluster**: Modify instance groups using the Cluster class\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "If you encounter issues during cluster creation:\n",
    "\n",
    "- Check AWS CloudFormation console for detailed error messages\n",
    "- Verify AWS credentials and permissions using `boto3.Session()`\n",
    "- Ensure resource quotas are sufficient\n",
    "- Review the cluster configuration parameters\n",
    "\n",
    "## Cleanup\n",
    "\n",
    "To avoid ongoing charges, remember to delete your cluster when no longer needed:\n",
    "\n",
    "```python\n",
    "# Delete cluster using sagemaker-core\n",
    "cluster = Cluster.get(cluster_name=cluster_name)\n",
    "cluster.delete()\n",
    "\n",
    "# Or delete the entire stack\n",
    "import boto3\n",
    "cf_client = boto3.client('cloudformation', region_name='us-east-2')\n",
    "cf_client.delete_stack(StackName=stack_name)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the complete HyperPod cluster creation workflow using the SDK:\n",
    "\n",
    "✅ **Initialized** cluster configuration with `HpClusterStack` class  \n",
    "✅ **Configured** cluster settings and tags programmatically  \n",
    "✅ **Created** cluster infrastructure with `cluster_stack.create()`  \n",
    "✅ **Monitored** deployment with `HpClusterStack.check_status()`  \n",
    "✅ **Listed** all clusters with `HpClusterStack.list()`  \n",
    "✅ **Updated** cluster configuration with `Cluster.update()`  \n",
    "✅ **Verified** cluster health with comprehensive checks  \n",
    "\n",
    "Your HyperPod cluster is now ready for distributed machine learning workloads using the SDK!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
