# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License"). You
# may not use this file except in compliance with the License. A copy of
# the License is located at
#
#     http://aws.amazon.com/apache2.0/
#
# or in the "license" file accompanying this file. This file is
# distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF
# ANY KIND, either express or implied. See the License for the specific
# language governing permissions and limitations under the License.

# Hydra configurations. SageMaker Hyperpod CLI use Hydra to manage start-job YAML files.
defaults:
  - override hydra/job_logging: stdout

hydra:
  run:
    dir: .
  output_subdir: null

training_cfg:
  # entry_script: Required. Path to the entry script of training/fine-tuning, this path should be inside container
  entry_script: /opt/pytorch-mnist/mnist.py
  # script_args: Optional. List of script arguments. Example of usage:
  # script_args:
  #  - --max_context_width: 4096
  #  - --num_layers: 32
  script_args: []
  run:
    # name: Required. Current Training Job name
    name: hyperpod-cli-test
    # nodes: Required. Number of nodes to use for current training
    nodes: 2
    # ntasks_per_node: Optional. Number of devices to use per node.
    # For CPU instances, default value will be 8; For GPU or TRN instances, default value
    # will be the accelerator cores number on the instance
    ntasks_per_node: 1
cluster:
  # cluster_type: Required. Currently, only support k8s cluster type
  cluster_type: k8s
  # instance_type: Required. SageMaker Hyperpod supported instance type only.
  instance_type: ml.c5.2xlarge
  # cluster_config: Required. Fields related to cluster configuration for each Training job run.
  cluster_config:
    # annotations: Optional. The annotations attached to the Training job.
    # To use SageMaker Hyperpod Job Auto Resume feature, set annotations like following example:
    #  annotations:
    #    sagemaker.amazonaws.com/enable-job-auto-resume: True
    #    sagemaker.amazonaws.com/job-max-retry-count: 1
    annotations: null
    # service_account_name: Optional. The name of service account associated with the namespace.
    service_account_name: null
    # persistent_volume_claims: Optional. The persistent volume claims, usually used to mount FSx
    persistent_volume_claims: null
    # namespace: Optional. The namespace to submit job. If not specify, Training job will submit to
    # the current namespace from Kubernetes context.
    namespace: kubeflow
    # custom_labels: Optional. Used to specify the name of the queue, which is created by the cluster admin users.
    # custom_labels:
    #   kueue.x-k8s.io/queue-name: low-priority-queue2
    custom_labels: null
    # priority_class_name: Optional. The priority for the job, which is created by the cluster admin users.
    priority_class_name: null
    # volumes: Optional. Used to mount temp path to container. Example of usage:
    # volumes:
    #  - volumeName: v1
    #    hostPath: /data
    #    mountPath: /data
    volumes: null
    # labal_selector: Optional. Defines Kubernetes node affinity to select nodes with labels. Following
    # config will choose SageMaker HyperPod health labels and prefer nodes with SageMaker Hyperpod burn-in
    # test passed label.
    label_selector:
      required:
        sagemaker.amazonaws.com/node-health-status:
          - Schedulable
      preferred:
        sagemaker.amazonaws.com/deep-health-check-status:
          - Passed
      weights:
        - 100
    # pullPolicy: Required. Kubernetes PyTorchJob pull policy to pull container, can be Always, IfNotPresent and Never
    pullPolicy: IfNotPresent
    # restartPolicy: Required. Kubernetes PyTorchJob restart policy. Can be OnFailure, Always or Never.
    # To use SageMaker Hyperpod AutoResume functionality, please set it to OnFailure.
    restartPolicy: OnFailure

# base_results_dir: Optional. Location to store the results, checkpoints and logs.
base_results_dir: ./result
# container: Required. Docker image to be used for Training Job
container: docker.io/kubeflowkatib/pytorch-mnist-cpu:v1beta1-bc09cfd

# env_vars: Optional. Environment variables passed to the training job.
env_vars:
  NCCL_DEBUG: INFO # Logging level for NCCL. Set to "INFO" for debug information
