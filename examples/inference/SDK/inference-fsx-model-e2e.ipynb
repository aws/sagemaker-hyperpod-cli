{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8caf125-ab9d-4655-a59e-edbaeed9e919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.hyperpod import list_clusters, set_cluster_context\n",
    "list_clusters(region='us-east-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765ef3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the HP cluster\n",
    "set_cluster_context('<my-cluster>', region='us-east-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f976ba-d113-4e73-9698-2e5d8c7c44f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.hyperpod.inference.config.hp_endpoint_config import FsxStorage, ModelSourceConfig, TlsConfig, EnvironmentVariables, ModelInvocationPort, ModelVolumeMount, Resources, Worker\n",
    "from sagemaker.hyperpod.inference.hp_endpoint import HPEndpoint\n",
    "import yaml\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f9a718-524a-4a3d-9885-31385c995c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "tls_config=TlsConfig(tls_certificate_output_s3_uri='s3://<my-tls-bucket-name>')\n",
    "\n",
    "model_source_config = ModelSourceConfig(\n",
    "    model_source_type='fsx',\n",
    "    model_location=\"<my-model-folder-in-fsx>\",\n",
    "    fsx_storage=FsxStorage(\n",
    "        file_system_id='<my-fs-id>'\n",
    "    ),\n",
    ")\n",
    "\n",
    "environment_variables = [\n",
    "    EnvironmentVariables(name=\"HF_MODEL_ID\", value=\"/opt/ml/model\"),\n",
    "    EnvironmentVariables(name=\"SAGEMAKER_PROGRAM\", value=\"inference.py\"),\n",
    "    EnvironmentVariables(name=\"SAGEMAKER_SUBMIT_DIRECTORY\", value=\"/opt/ml/model/code\"),\n",
    "    EnvironmentVariables(name=\"MODEL_CACHE_ROOT\", value=\"/opt/ml/model\"),\n",
    "    EnvironmentVariables(name=\"SAGEMAKER_ENV\", value=\"1\"),\n",
    "]\n",
    "\n",
    "worker = Worker(\n",
    "    image='763104351884.dkr.ecr.us-east-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.4.0-tgi2.3.1-gpu-py311-cu124-ubuntu22.04-v2.0',\n",
    "    model_volume_mount=ModelVolumeMount(\n",
    "        name='model-weights',\n",
    "    ),\n",
    "    model_invocation_port=ModelInvocationPort(container_port=8080),\n",
    "    resources=Resources(\n",
    "            requests={\"cpu\": \"30000m\", \"nvidia.com/gpu\": 1, \"memory\": \"100Gi\"},\n",
    "            limits={\"nvidia.com/gpu\": 1}\n",
    "    ),\n",
    "    environment_variables=environment_variables,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae599413-e275-47c3-9dca-05b80b1bb6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsx_endpoint = HPEndpoint(\n",
    "    endpoint_name='<my-endpoint-name>',\n",
    "    instance_type='ml.g5.8xlarge',\n",
    "    model_name='deepseek15b-fsx-test-pysdk',\n",
    "    tls_config=tls_config,\n",
    "    model_source_config=model_source_config,\n",
    "    worker=worker,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf04c78e-745d-4530-8342-216cf1fbcfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsx_endpoint.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2cfae4-a056-465d-823a-75f5b6b9a495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poll status\n",
    "t = 0\n",
    "timeout = 600  # 600 seconds timeout  \n",
    "interval = 15  # poll every 15 seconds\n",
    "\n",
    "while t < timeout:\n",
    "    # use refresh to fetch latest status\n",
    "    fsx_endpoint.refresh()\n",
    "\n",
    "    print('Refreshing instance status...')\n",
    "\n",
    "    try:\n",
    "        # deployment status will be available immediately\n",
    "        deployment_status = fsx_endpoint.status.deploymentStatus.deploymentObjectOverallState\n",
    "        if deployment_status== 'DeploymentFailed':\n",
    "            print('Deployment failed!')\n",
    "            break\n",
    "\n",
    "        # endpoint status will appear be available from refresh() at some point\n",
    "        endpoint_status = fsx_endpoint.status.endpoints.sagemaker.state\n",
    "        if endpoint_status == 'CreationCompleted':\n",
    "            print('Endpoint is available!')\n",
    "            break\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    time.sleep(interval)\n",
    "    t += interval\n",
    "\n",
    "if t >= timeout:\n",
    "    print('Endpoint creation timed out!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74033ba-1a49-4953-b705-d0f95b867cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print endpoint in yaml\n",
    "def print_yaml(endpoint):\n",
    "    print(yaml.dump(endpoint.model_dump(exclude_none=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d606c862-0f03-4cd9-9324-c5960d6be362",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list all endpoints\n",
    "endpoint_list = HPEndpoint.list()\n",
    "print_yaml(endpoint_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31b2d84-78e3-4c79-bb2c-e0844601492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = HPEndpoint.get(name='<my-endpoint-name>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d65df2-fe0c-4e3c-b584-dfd10e9e7264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke\n",
    "data='{\"inputs\": \"What is the capital of Japan?\"}'\n",
    "\n",
    "# invoke\n",
    "endpoint.invoke(body=data).body.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b3a2ce-6531-4d8d-bd17-e1daabf557cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete endpoint\n",
    "endpoint.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
